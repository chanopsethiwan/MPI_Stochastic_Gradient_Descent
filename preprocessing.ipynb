{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a580edc",
   "metadata": {},
   "source": [
    "## Step 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "997db289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c37144d8a4c410b96d220b12a555925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing mean and variance:   0%|          | 0/397.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid rows after outlier removal: 37560523\n",
      "Mean: [  1.40264048   3.55686178   1.35107429 165.01859841 162.83035814\n",
      "   1.21437838   1.05755672   0.28915475]\n",
      "Std: [ 0.965228   53.85523056  5.30225853 64.84880916 70.09427412  0.43384368\n",
      "  1.26935216  0.81894926]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e633c1925e4a6a921993c0641d0b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing and saving to final_normalized.npy:   0%|          | 0/397.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37560523, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "file_path = \"nytaxi2022.csv\"\n",
    "output_path = \"final_normalized.npy\"\n",
    "\n",
    "num_lines = sum(1 for _ in open(file_path, mode=\"rb\")) - 1\n",
    "target_cols = [\"passenger_count\",\"trip_distance\",\"RatecodeID\",\n",
    "    \"PULocationID\",\"DOLocationID\",\"payment_type\",\"extra\"]   # numeric cols to normalize\n",
    "start_col = \"tpep_pickup_datetime\"\n",
    "end_col = \"tpep_dropoff_datetime\"\n",
    "TARGET = \"total_amount\"\n",
    "remove_outliers_cols = [\"trip_distance\", \"duration\"]\n",
    "chunksize = 100000\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# HELPER: Outlier filter\n",
    "# ----------------------------------------------------------\n",
    "def remove_outliers(df):\n",
    "    return df[(df[\"total_amount\"] > 0) &\n",
    "        (df[\"total_amount\"] < 300) &\n",
    "        (df[\"trip_distance\"] > 0) &\n",
    "        (df[\"duration\"] > 0) &\n",
    "        (df[\"duration\"] <= 180)]\n",
    "\n",
    "# ---------- PASS 1: compute mean & std for target + duration ----------\n",
    "all_numeric = target_cols + [\"duration\"]\n",
    "\n",
    "count = 0\n",
    "mean = np.zeros(len(all_numeric))\n",
    "M2 = np.zeros(len(all_numeric))\n",
    "\n",
    "for chunk in tqdm(pd.read_csv(\n",
    "    file_path, \n",
    "    chunksize=chunksize, \n",
    "    usecols=target_cols + [start_col, end_col, TARGET], \n",
    "    parse_dates=[start_col, end_col],\n",
    "    date_format=\"%m/%d/%Y %I:%M:%S %p\",\n",
    "), total=np.ceil(num_lines/chunksize), desc = \"Computing mean and variance\"):\n",
    "    # duration in hours\n",
    "    chunk[\"duration\"] = (chunk[end_col] - chunk[start_col]).dt.total_seconds() / 3600.0\n",
    "    \n",
    "    # drop NaNs + outliers\n",
    "    data = chunk.dropna(subset=all_numeric)\n",
    "    data = remove_outliers(data)\n",
    "    if data.empty:\n",
    "        continue\n",
    "    \n",
    "    values = data[all_numeric].to_numpy()\n",
    "    for row in values:\n",
    "        count += 1\n",
    "        delta = row - mean\n",
    "        mean += delta / count\n",
    "        delta2 = row - mean\n",
    "        M2 += delta * delta2\n",
    "    \n",
    "\n",
    "variance = M2 / (count - 1)\n",
    "std = np.sqrt(variance)\n",
    "\n",
    "print(\"Valid rows after outlier removal:\", count)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)\n",
    "\n",
    "# ---------- PASS 2: normalize + cyclic + save ----------\n",
    "n_features = len(all_numeric) + 6 # 6 cyclic features\n",
    "shape = (count, n_features + 1) # +1 target value\n",
    "fp = np.memmap(output_path, dtype=\"float32\", mode=\"w+\", shape=shape)\n",
    "\n",
    "row_start = 0\n",
    "for chunk in tqdm(pd.read_csv(\n",
    "    file_path, \n",
    "    chunksize=chunksize, \n",
    "    usecols=target_cols + [start_col, end_col, TARGET], \n",
    "    parse_dates=[start_col, end_col],\n",
    "    date_format=\"%m/%d/%Y %I:%M:%S %p\",\n",
    "), total=np.ceil(num_lines/chunksize), desc = f\"Preprocessing and saving to {output_path}\"):\n",
    "    chunk[\"duration\"] = (chunk[end_col] - chunk[start_col]).dt.total_seconds() / 3600.0\n",
    "    \n",
    "    # drop NaNs + outliers\n",
    "    data = chunk.dropna(subset=all_numeric)\n",
    "    data = remove_outliers(data)\n",
    "    if data.empty:\n",
    "        continue\n",
    "    \n",
    "    # cyclic features from start_time\n",
    "    dt = data[start_col]\n",
    "    dow, month, hour = dt.dt.dayofweek, dt.dt.month, dt.dt.hour\n",
    "\n",
    "    cyclic_features = np.vstack([\n",
    "        np.sin(2*np.pi*dow/7),  np.cos(2*np.pi*dow/7),\n",
    "        np.sin(2*np.pi*(month-1)/12), np.cos(2*np.pi*(month-1)/12),\n",
    "        np.sin(2*np.pi*hour/24), np.cos(2*np.pi*hour/24)\n",
    "    ]).T\n",
    "    \n",
    "    # normalize numeric cols\n",
    "    normed = ((data[all_numeric].to_numpy() - mean) / std).astype(\"float32\") \n",
    "    \n",
    "    # stack\n",
    "    arr = np.hstack([normed, \n",
    "                     cyclic_features.astype(\"float32\"), \n",
    "                     data[TARGET].values.reshape((-1,1))])\n",
    "    \n",
    "    n = len(arr)\n",
    "    fp[row_start:row_start+n, :] = arr\n",
    "    row_start += n\n",
    "\n",
    "fp.flush()\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3bb756b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21730890, 13)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_memmap_array = np.memmap(\"final_normalized.npy\", dtype=\"float32\", mode='r')\n",
    "new = my_memmap_array.reshape((-1,13))\n",
    "new.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
