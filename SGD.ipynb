{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe20b5a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Plan\n",
    "* Assuming the input has n features (I think it actually contains 9 features)\n",
    "* The neural network only have one hidden layer which contains the following\n",
    "    * Weights for each input features (w_jk in the instruction) and each neuron\n",
    "    * Bias for each neuron\n",
    "    * Activation function sigma \n",
    "    * Weights to multiply by result after activation function\n",
    "    * Bias to add to result after activation function\n",
    "\n",
    "* First function will compute the sum of the gradient of loss of each data inputted\n",
    "* Second function will take in the average loss and then update all the weights inside them accordingly. \n",
    "Maybe use a dictionary of list to store different weights like this: \n",
    "\n",
    "{\n",
    "    weights_features: a matrix (arrary of array) with number of neurons row and number of features column,\n",
    "    bias_features: an array with number of neurons item (amount of bias parameter does not depend on number of features),\n",
    "    weights_after_activation: This is the weights after activation layer \n",
    "    bias_after_activation: This is the output layer bias\n",
    "    }\n",
    "\n",
    "To make it simple to understand, you can do a for loop for each feature and then just find out approximationa and gradient for each with the function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf286df",
   "metadata": {},
   "source": [
    "### input features\n",
    "The input features features_list should be a list with the value of the following predictor strictly in this order:\n",
    "[tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, RatecodeID, PULocationID, DOLocationID, payment_type, extra]\n",
    "\n",
    "NOTE: Will check again whether this will need to be a numpy array or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490f50e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c006014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39656098 entries, 0 to 39656097\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Dtype              \n",
      "---  ------                 -----              \n",
      " 0   tpep_pickup_datetime   datetime64[ns, UTC]\n",
      " 1   tpep_dropoff_datetime  datetime64[ns, UTC]\n",
      " 2   passenger_count        float64            \n",
      " 3   trip_distance          float64            \n",
      " 4   RatecodeID             float64            \n",
      " 5   PULocationID           int64              \n",
      " 6   DOLocationID           int64              \n",
      " 7   payment_type           int64              \n",
      " 8   extra                  float64            \n",
      " 9   total_amount           float64            \n",
      " 10  trip_duration_min      float32            \n",
      " 11  pickup_hour            float32            \n",
      " 12  pickup_dow             float32            \n",
      "dtypes: datetime64[ns, UTC](2), float32(3), float64(5), int64(3)\n",
      "memory usage: 3.4 GB\n"
     ]
    }
   ],
   "source": [
    "# import the data\n",
    "data = pd.read_parquet('data/nytaxi2022_cleaned.parquet')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a92a0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>extra</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>trip_duration_min</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:35:40+00:00</td>\n",
       "      <td>2022-01-01 00:53:29+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.95</td>\n",
       "      <td>17.816668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 00:33:43+00:00</td>\n",
       "      <td>2022-01-01 00:42:07+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>13.30</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 00:53:21+00:00</td>\n",
       "      <td>2022-01-01 01:02:19+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.56</td>\n",
       "      <td>8.966666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 00:25:21+00:00</td>\n",
       "      <td>2022-01-01 00:35:23+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11.80</td>\n",
       "      <td>10.033334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 00:36:48+00:00</td>\n",
       "      <td>2022-01-01 01:14:20+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30.30</td>\n",
       "      <td>37.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tpep_pickup_datetime     tpep_dropoff_datetime  passenger_count  \\\n",
       "0 2022-01-01 00:35:40+00:00 2022-01-01 00:53:29+00:00              2.0   \n",
       "1 2022-01-01 00:33:43+00:00 2022-01-01 00:42:07+00:00              1.0   \n",
       "2 2022-01-01 00:53:21+00:00 2022-01-01 01:02:19+00:00              1.0   \n",
       "3 2022-01-01 00:25:21+00:00 2022-01-01 00:35:23+00:00              1.0   \n",
       "4 2022-01-01 00:36:48+00:00 2022-01-01 01:14:20+00:00              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID  PULocationID  DOLocationID  payment_type  extra  \\\n",
       "0           3.80         1.0           142           236             1    3.0   \n",
       "1           2.10         1.0           236            42             1    0.5   \n",
       "2           0.97         1.0           166           166             1    0.5   \n",
       "3           1.09         1.0           114            68             2    0.5   \n",
       "4           4.30         1.0            68           163             1    0.5   \n",
       "\n",
       "   total_amount  trip_duration_min  pickup_hour  pickup_dow  \n",
       "0         21.95          17.816668          0.0         5.0  \n",
       "1         13.30           8.400000          0.0         5.0  \n",
       "2         10.56           8.966666          0.0         5.0  \n",
       "3         11.80          10.033334          0.0         5.0  \n",
       "4         30.30          37.533333          0.0         5.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ea58987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final X,y: (39656098, 10) (39656098,)\n"
     ]
    }
   ],
   "source": [
    "# performing train test split\n",
    "\n",
    "NUM = [\"passenger_count\",\"trip_distance\",\"extra\",\"trip_duration_min\",\"pickup_hour\",\"pickup_dow\"]\n",
    "CAT = [\"RatecodeID\",\"PULocationID\",\"DOLocationID\",\"payment_type\"]\n",
    "TARGET = \"total_amount\"\n",
    "\n",
    "X, y = data[NUM + CAT], data[TARGET].astype(\"float32\")\n",
    "print(\"final X,y:\", X.shape, y.shape)   # must show non-zero rows\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c4f77c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 27759268 entries, 25756598 to 21081788\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   passenger_count    float64\n",
      " 1   trip_distance      float64\n",
      " 2   extra              float64\n",
      " 3   trip_duration_min  float32\n",
      " 4   pickup_hour        float32\n",
      " 5   pickup_dow         float32\n",
      " 6   RatecodeID         float64\n",
      " 7   PULocationID       int64  \n",
      " 8   DOLocationID       int64  \n",
      " 9   payment_type       int64  \n",
      "dtypes: float32(3), float64(4), int64(3)\n",
      "memory usage: 2.0 GB\n"
     ]
    }
   ],
   "source": [
    "# preprocess data into desired features_list form\n",
    "Xtr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f02e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only use this function at the beginning to initialise weights and bias in the desired format, the rest should be just you inputting the newly computed weights and bias from backpropagation\n",
    "# # Here is an example using Xavier initialisation\n",
    "# def initialise_weights(features_list, number_of_neurons):\n",
    "#     weights_dict = {}\n",
    "#     weights_dict['weights_features'] = np.random.rand(number_of_neurons, len(features_list))\n",
    "#     weights_dict['bias_features'] = np.random.rand(number_of_neurons)\n",
    "#     weights_dict['output_weights'] = np.random.rand(number_of_neurons)\n",
    "#     weights_dict['output_bias'] = np.random.rand(1)[0]\n",
    "#     return weights_dict\n",
    "\n",
    "# using Xavier initialisation (optional: test other initialisation methods)\n",
    "# Xavier initialisation aims to:\n",
    "# The variance of activations the same across layers (forward pass stability).\n",
    "# The variance of gradients the same across layers (backward pass stability).\n",
    "# This reduces risk of vanishing/exploding gradients and allows stable signal propragation\n",
    "# through the deep neural network\n",
    "\n",
    "def initialise_weights(features_list, number_of_neurons):\n",
    "    n_in = len(features_list)\n",
    "    \n",
    "    # Xavier/Glorot uniform initialization\n",
    "    limit_hidden = np.sqrt(1 / (n_in + number_of_neurons))\n",
    "    limit_output = np.sqrt(1 / (number_of_neurons + 1))  # +1 for scalar output neuron\n",
    "    \n",
    "    weights_dict = {}\n",
    "    # Hidden layer weights and bias\n",
    "    weights_dict['weights_features'] = np.random.uniform(-limit_hidden, limit_hidden, (number_of_neurons, n_in))\n",
    "    weights_dict['bias_features'] = np.zeros(number_of_neurons)  # usually initialised to 0\n",
    "    weights_dict['weights_after_activation'] = np.random.uniform(-limit_output, limit_output, number_of_neurons)\n",
    "    weights_dict['bias_after_activation'] = 0.0  # usually initialised to 0\n",
    "    return weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae07557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function list with their derivative\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def diff_relu(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "def diff_sigmoid(x):\n",
    "    sig = sigmoid(x)\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "def diff_tanh(x):\n",
    "    return 1 - np.tanh(x)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diff(weights_dict, features_list, actual_val, activation_func):\n",
    "    # perform matrix multiplication of features and weights\n",
    "    z = np.dot(weights_dict['weights_features'], features_list) + weights_dict['bias_features']\n",
    "    # apply activation function\n",
    "    if activation_func == 'relu':\n",
    "        activated_output = relu(z)\n",
    "    elif activation_func == 'sigmoid':\n",
    "        activated_output = sigmoid(z)\n",
    "    elif activation_func == 'tanh':\n",
    "        activated_output = tanh(z)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported activation function\")\n",
    "    \n",
    "    # calculate final output\n",
    "    final_output = np.dot(weights_dict['weights_after_activation'], activated_output) + weights_dict['bias_after_activation']\n",
    "\n",
    "    # calculate loss (mean squared error)\n",
    "    diff = final_output - actual_val\n",
    "    # loss = (final_output - actual_val) ** 2\n",
    "\n",
    "    return diff, z # z is the output pre activation, will be useful in the calculate gradient step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feebe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function should be used in parallel to calculate RMSE of the whole process, this is essential to record\n",
    "# RMSE and check convergence of the models (so if it does not decrase,\n",
    "# iteration should terminate itself)\n",
    "# NOTE THIS FUNCTION OUTPUTS SQUARED DIFFERENCE, NOT RMSE\n",
    "def calculate_squared_diff(weights_dict, data_batch, activation_func):\n",
    "    total_loss = 0\n",
    "    for features_list, actual_val in data_batch:\n",
    "        loss = calculate_diff(weights_dict, features_list, actual_val, activation_func)[0] ** 2\n",
    "        total_loss += loss\n",
    "    return total_loss, len(data_batch) # returns the total loss and number of samples in the mini batch in this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44240cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the gradient of the model output with respect to the model parameters.\n",
    "# Must calculate grad f first as well\n",
    "def calculate_gradients(weights_dict, data_batch, activation_func):\n",
    "    # using chain rule we can obtain the grad equation for weights feature to be:\n",
    "    data_batch_size = len(data_batch)\n",
    "    for features_list, actual_val in data_batch:\n",
    "        # absolute difference \n",
    "        error, z = calculate_diff(weights_dict, features_list, actual_val, activation_func) \n",
    "        \n",
    "        # apply activation function\n",
    "        if activation_func == 'relu':\n",
    "            activated_output = relu(z)\n",
    "            activated_derivative = diff_relu(z)\n",
    "        elif activation_func == 'sigmoid':\n",
    "            activated_output = sigmoid(z)\n",
    "            activated_derivative = diff_sigmoid(z)\n",
    "        elif activation_func == 'tanh':\n",
    "            activated_output = tanh(z)\n",
    "            activated_derivative = diff_tanh(z)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "        \n",
    "        # Gradients initialization with same shape as weights\n",
    "        grad_weights_features = np.zeros_like(weights_dict['weights_features'])\n",
    "        grad_bias_features = np.zeros_like(weights_dict['bias_features'])\n",
    "        grad_weights_after_activation = np.zeros_like(weights_dict['weights_after_activation'])\n",
    "        grad_bias_after_activation = 0.0 # bias_after_activation is just scalar\n",
    "\n",
    "        # Gradient w.r.t. output layer weights and bias\n",
    "        grad_weights_after_activation += error * activated_output\n",
    "        grad_bias_after_activation += error\n",
    "\n",
    "        # Gradient w.r.t. hidden layer weights and bias\n",
    "        delta_hidden = error * weights_dict['weights_after_activation'] * activated_derivative\n",
    "        grad_weights_features += np.outer(delta_hidden, features_list)\n",
    "        grad_bias_features += delta_hidden\n",
    "\n",
    "    gradient_dict = {\n",
    "        'grad_weights_features': grad_weights_features/data_batch_size,\n",
    "        'grad_bias_features': grad_bias_features/data_batch_size,\n",
    "        'grad_weights_after_activation': grad_weights_after_activation/data_batch_size,\n",
    "        'grad_bias_features': grad_bias_after_activation/data_batch_size\n",
    "        }\n",
    "\n",
    "    return gradient_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b5e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights_dict, gradients, learning_rate):\n",
    "    # Update weights and biases using the computed gradients\n",
    "    weights_dict['weights_features'] -= learning_rate * gradients['grad_weights_features']\n",
    "    weights_dict['bias_features'] -= learning_rate * gradients['grad_bias_features']\n",
    "    weights_dict['weights_after_activation'] -= learning_rate * gradients['grad_weights_after_activation']\n",
    "    weights_dict['bias_after_activation'] -= learning_rate * gradients['grad_bias_after_activation']\n",
    "    return weights_dict\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stockulator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
