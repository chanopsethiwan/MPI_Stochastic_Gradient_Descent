{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e937e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938fe040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/27/1nzvqhpd5f7bc_n8rgyv1v4h0000gn/T/ipykernel_18279/1526527318.py:1: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('nytaxi2022.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2022 12:35:40 AM</td>\n",
       "      <td>01/01/2022 12:53:29 AM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>01/01/2022 12:33:43 AM</td>\n",
       "      <td>01/01/2022 12:42:07 AM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2022 12:53:21 AM</td>\n",
       "      <td>01/01/2022 01:02:19 AM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2022 12:25:21 AM</td>\n",
       "      <td>01/01/2022 12:35:23 AM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>114</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2022 12:36:48 AM</td>\n",
       "      <td>01/01/2022 01:14:20 AM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  01/01/2022 12:35:40 AM  01/01/2022 12:53:29 AM              2.0   \n",
       "1         1  01/01/2022 12:33:43 AM  01/01/2022 12:42:07 AM              1.0   \n",
       "2         2  01/01/2022 12:53:21 AM  01/01/2022 01:02:19 AM              1.0   \n",
       "3         2  01/01/2022 12:25:21 AM  01/01/2022 12:35:23 AM              1.0   \n",
       "4         2  01/01/2022 12:36:48 AM  01/01/2022 01:14:20 AM              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           3.80         1.0                  N           142           236   \n",
       "1           2.10         1.0                  N           236            42   \n",
       "2           0.97         1.0                  N           166           166   \n",
       "3           1.09         1.0                  N           114            68   \n",
       "4           4.30         1.0                  N            68           163   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1         14.5    3.0      0.5        3.65           0.0   \n",
       "1             1          8.0    0.5      0.5        4.00           0.0   \n",
       "2             1          7.5    0.5      0.5        1.76           0.0   \n",
       "3             2          8.0    0.5      0.5        0.00           0.0   \n",
       "4             1         23.5    0.5      0.5        3.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    0.3         21.95                   2.5          0.0  \n",
       "1                    0.3         13.30                   0.0          0.0  \n",
       "2                    0.3         10.56                   0.0          0.0  \n",
       "3                    0.3         11.80                   2.5          0.0  \n",
       "4                    0.3         30.30                   2.5          0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('nytaxi2022.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9887dec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39656098, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef86a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# convert \"\" or whitespace-only cells to NA so pandas counts them as missing\n",
    "df = df.replace(r\"^\\s*$\", pd.NA, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3236d3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                       0\n",
       "tpep_pickup_datetime           0\n",
       "tpep_dropoff_datetime          0\n",
       "passenger_count          1368303\n",
       "trip_distance                  0\n",
       "RatecodeID               1368303\n",
       "store_and_fwd_flag       1368303\n",
       "PULocationID                   0\n",
       "DOLocationID                   0\n",
       "payment_type                   0\n",
       "fare_amount                    0\n",
       "extra                          0\n",
       "mta_tax                        0\n",
       "tip_amount                     0\n",
       "tolls_amount                   0\n",
       "improvement_surcharge          0\n",
       "total_amount                   0\n",
       "congestion_surcharge     1368303\n",
       "airport_fee              1368303\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of missing row within a columns\n",
    "df.isna().sum()            # per-column counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "021f9803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(1368303), np.float64(3.45))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df)\n",
    "cols = [\"passenger_count\",\"RatecodeID\",\"store_and_fwd_flag\",\"congestion_surcharge\",\"airport_fee\"]\n",
    "\n",
    "miss_tbl = (\n",
    "    df[cols].isna().sum()\n",
    "      .to_frame(\"missing\")\n",
    "      .assign(pct=lambda t: (t[\"missing\"]/N*100).round(2))\n",
    ")\n",
    "miss_tbl  # quick table\n",
    "\n",
    "# Are the *same* rows missing all five?\n",
    "co_missing = df[cols].isna().all(axis=1)\n",
    "co_missing.sum(), (co_missing.mean()*100).round(2)  # count & %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61f5f1",
   "metadata": {},
   "source": [
    "Output confirms that the same 1,368,303 (~3.45%) are missing values in these columns: passenger_count, RatecodeID, store_and_fwd_flag, congestion_surcharge, airport_fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa2ec5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep:  ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'PULocationID', 'DOLocationID', 'payment_type', 'extra']\n",
      "DROP (leakage):  ['fare_amount', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge', 'airport_fee']\n",
      "DROP (constant):  []\n",
      "DROP (very missing):  []\n"
     ]
    }
   ],
   "source": [
    "TARGET = \"total_amount\"\n",
    "\n",
    "allowed = [\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\n",
    "    \"passenger_count\",\"trip_distance\",\"RatecodeID\",\n",
    "    \"PULocationID\",\"DOLocationID\",\"payment_type\",\"extra\"]\n",
    "\n",
    "leakage = [\"fare_amount\",\"mta_tax\",\"tip_amount\",\"tolls_amount\",\n",
    "    \"improvement_surcharge\",\"congestion_surcharge\",\"airport_fee\", TARGET]\n",
    "\n",
    "present = [c for c in df.columns if c in allowed]\n",
    "leak_present = [c for c in df.columns if c in leakage and c != TARGET]\n",
    "\n",
    "# optional: remove near-constant and very-missing among the allowed set\n",
    "missing = df[present].isna().mean().sort_values(ascending=False)\n",
    "const_like = [c for c in present if df[c].nunique(dropna=True) <= 1]\n",
    "very_missing = [c for c in present if missing[c] > 0.40] #40% threshold; tweak\n",
    "\n",
    "keep = [c for c in present if c not in const_like and c not in very_missing]\n",
    "\n",
    "print(\"Keep: \", keep)\n",
    "print(\"DROP (leakage): \", leak_present)\n",
    "print(\"DROP (constant): \", const_like)\n",
    "print(\"DROP (very missing): \", very_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd86f7",
   "metadata": {},
   "source": [
    "Engineer the time features column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3969d62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/27/1nzvqhpd5f7bc_n8rgyv1v4h0000gn/T/ipykernel_18279/3375058208.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  m[c] = pd.to_datetime(m[c], errors=\"coerce\", utc=True)\n",
      "/var/folders/27/1nzvqhpd5f7bc_n8rgyv1v4h0000gn/T/ipykernel_18279/3375058208.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  m[c] = pd.to_datetime(m[c], errors=\"coerce\", utc=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "m = df[keep + [TARGET]].copy()\n",
    "for c in [\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\"]:\n",
    "    m[c] = pd.to_datetime(m[c], errors=\"coerce\", utc=True)\n",
    "\n",
    "m[\"trip_duration_min\"] = (m[\"tpep_dropoff_datetime\"] - m[\"tpep_pickup_datetime\"]).dt.total_seconds()/60\n",
    "m[\"pickup_hour\"] = m[\"tpep_pickup_datetime\"].dt.hour.astype(\"Int8\")\n",
    "m[\"pickup_dow\"]  = m[\"tpep_pickup_datetime\"].dt.dayofweek.astype(\"Int8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "195bce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all present: True\n",
      "pickup dtype: datetime64[ns, UTC] | dropoff dtype: datetime64[ns, UTC]\n",
      "duration dtype: float64 | hour dtype: Int8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tpep_pickup_datetime     0\n",
       "tpep_dropoff_datetime    0\n",
       "trip_duration_min        0\n",
       "pickup_hour              0\n",
       "pickup_dow               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_dt\n",
    "\n",
    "# required columns present?\n",
    "req = [\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\n",
    "       \"trip_duration_min\",\"pickup_hour\",\"pickup_dow\"]\n",
    "print(\"all present:\", set(req).issubset(m.columns))\n",
    "\n",
    "# dtypes look right?\n",
    "print(\"pickup dtype:\", m[\"tpep_pickup_datetime\"].dtype, \"| dropoff dtype:\", m[\"tpep_dropoff_datetime\"].dtype)\n",
    "print(\"duration dtype:\", m[\"trip_duration_min\"].dtype, \"| hour dtype:\", m[\"pickup_hour\"].dtype)\n",
    "\n",
    "# NAs\n",
    "m[req].isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47749114",
   "metadata": {},
   "source": [
    "Time-based split (avoid leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fda7752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27759268, 11896830)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET = \"total_amount\"\n",
    "NUM = [\"passenger_count\",\"trip_distance\",\"extra\",\"trip_duration_min\",\"pickup_hour\",\"pickup_dow\"]\n",
    "CAT = [\"RatecodeID\",\"PULocationID\",\"DOLocationID\",\"payment_type\"]\n",
    "\n",
    "ms = m.sort_values(\"tpep_pickup_datetime\")\n",
    "cut = int(len(ms)*0.70)\n",
    "train, test = ms.iloc[:cut], ms.iloc[cut:]\n",
    "\n",
    "Xtr, ytr = train[NUM + CAT], train[TARGET].astype(\"float32\")\n",
    "Xte, yte = test [NUM + CAT], test [TARGET].astype(\"float32\")\n",
    "\n",
    "len(train), len(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8615fe",
   "metadata": {},
   "source": [
    "* Splitting by time to match how the model will be used in real lift: trained on the past, predicts the future.\n",
    "\n",
    "* A random split can quietly inflate scores for time-dependent data like taxi trips\n",
    "\n",
    "Why time-based split?\n",
    "* Realistic evaluation: Testing on later periods simulates that\n",
    "* Avoid look-ahead leakage: Global steps (impute medians, scaling, ont-hot categories) must be learned on train only. If future rows is mix into training data, future information might be leak\n",
    "* Handles temporal correlation: Trips close in time share weather, traffic, events, policy changes. Random splits sprinkle near-identical conditions across train/test -> over-optimistic metrics\n",
    "* Detects drift: Fare/behavior shift by month/season. A chronological split shows how well the moel generalizes to a new regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7cf1df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 1.7.2\n",
      "python: /Users/chrisnjw/.pyenv/versions/myproj-311/bin/python\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Signature (y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn, sys, inspect\n",
    "print(\"sklearn:\", sklearn.__version__)\n",
    "print(\"python:\", sys.executable)\n",
    "inspect.signature(__import__(\"sklearn.metrics\").metrics.mean_squared_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "362c5d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.399168288871747, np.float64(55.5506942344371), 0.07257096419322462)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mae = mean_absolute_error(yte, pred)\n",
    "\n",
    "try:\n",
    "    rmse = mean_squared_error(yte, pred, squared=False)  # new API\n",
    "except TypeError:\n",
    "    rmse = np.sqrt(mean_squared_error(yte, pred))        # fallback for old sklearn\n",
    "\n",
    "r2  = r2_score(yte, pred)\n",
    "(mae, rmse, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2de5df6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.399168288871747,\n",
       " np.float64(55.5506942344371),\n",
       " 0.07257096419322462,\n",
       " 11.60715389251709,\n",
       " np.float64(57.711281748161035))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "baseline = np.full_like(yte, fill_value=float(ytr.mean()))\n",
    "b_mae = mean_absolute_error(yte, baseline)\n",
    "try:\n",
    "    b_rmse = mean_squared_error(yte, baseline, squared=False)\n",
    "except TypeError:\n",
    "    b_rmse = np.sqrt(mean_squared_error(yte, baseline))\n",
    "\n",
    "mae, rmse, r2, b_mae, b_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a149cd42",
   "metadata": {},
   "source": [
    "Baseline (Ridge) with proper preprocessing in a pipleline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9666c640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8779829572318527, np.float64(6.585973441997223), 0.8788138401564854)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "TARGET = \"total_amount\"\n",
    "NUM = [\"passenger_count\",\"trip_distance\",\"extra\",\"trip_duration_min\",\"pickup_hour\",\"pickup_dow\"]\n",
    "CAT = [\"RatecodeID\",\"PULocationID\",\"DOLocationID\",\"payment_type\"]\n",
    "\n",
    "Xtr, ytr = train[NUM+CAT], train[TARGET].astype(\"float32\")\n",
    "Xte, yte = test [NUM+CAT], test [TARGET].astype(\"float32\")\n",
    "\n",
    "pre_tree = ColumnTransformer([\n",
    "    (\"num\", SimpleImputer(strategy=\"median\"), NUM),\n",
    "    (\"cat\", Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"oh\",  OneHotEncoder(handle_unknown=\"ignore\", min_frequency=5))  # collapse rare cats\n",
    "    ]), CAT),\n",
    "])\n",
    "\n",
    "rf = Pipeline([\n",
    "    (\"pre\", pre_tree),\n",
    "    (\"est\", RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=20,            # cap depth for speed/overfit control\n",
    "        min_samples_leaf=5,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# warm up on a sample; then remove these two lines for full fit\n",
    "idx = Xtr.sample(n=1_000_000, random_state=42).index\n",
    "rf.fit(Xtr.loc[idx], ytr.loc[idx])\n",
    "\n",
    "# quick eval on a slice; then remove head(...) for full eval\n",
    "pred = rf.predict(Xte.head(500_000))\n",
    "\n",
    "# metrics (robust to sklearn version)\n",
    "mae = mean_absolute_error(yte.head(500_000), pred)\n",
    "try:\n",
    "    rmse = mean_squared_error(yte.head(500_000), pred, squared=False)\n",
    "except TypeError:\n",
    "    rmse = np.sqrt(mean_squared_error(yte.head(500_000), pred))\n",
    "r2 = r2_score(yte.head(500_000), pred)\n",
    "(mae, rmse, r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56941edb",
   "metadata": {},
   "source": [
    "y = dollar fare I am predicting\n",
    "X = numeric + categorical predictors based on my time-based split\n",
    "\n",
    "* Train 300 trees, each grown (up to depth 20) on the 1M training rows after OHE \n",
    "\n",
    "MAE = 1.88 dollars\n",
    "RMSE = 6.59\n",
    "R^2 = 0.879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791603e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (myproj)",
   "language": "python",
   "name": "myproj-311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
